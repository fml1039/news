{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "# Author: Schicheng Zhang (bottle1039@gmail.com) <--- if you have a more permanent email messsage use that\n",
    "'''\n",
    "This web scrapper allows one to scrape news information for a particular topic\n",
    " in a particular time. This is the traditional way to obtain search result from \n",
    " this website, which is directly add parameters to the actual query url. \n",
    "\n",
    "Note there can be replicated data as the website post the same article in different categories \n",
    "'''\n",
    "import datetime, time, bs4, urllib2, smtplib\n",
    "import re # for regular expression\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.support.ui import Select\n",
    "import os.path, os\n",
    "from httplib import BadStatusLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_location = ''\n",
    "\n",
    "# Parameters definition\n",
    "my_key_words = \"日本+地震\"\n",
    "search_url = \"http://zhannei.baidu.com/cse/search?q=@key&p=@page&s=16378496155419916178&entry=1&area=2\"\n",
    "init_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for obtain job list\n",
    "def obtain_page_html(page_url):\n",
    "    page_url = str(page_url)\n",
    "    print ('start download from')\n",
    "    print page_url\n",
    "    page_html = urllib2.urlopen(urllib2.Request(page_url)) \n",
    "\n",
    "    # Use beautifulsoup to parse the content\n",
    "    page_html = BeautifulSoup(page_html.read(), 'html.parser')\n",
    "    print 'Page obtained'\n",
    "    return page_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_search_query(page_id, key_words, address):\n",
    "    search_query = str(address).replace('@page',str(page_id)).replace('@key', str(key_words))\n",
    "    return search_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_search_information(result_object_list):\n",
    "    result_str = ''\n",
    "    for result_object in result_object_list:\n",
    "        result_object = BeautifulSoup(str(result_object), 'html.parser')\n",
    "        news_title = result_object.find('a').getText().encode('utf-8').replace('\\n','').replace('\\r','').replace(',','')\n",
    "        news_url = result_object.find('a')['href']\n",
    "        news_date = result_object.find('span',{'class':'c-showurl'}).getText().encode('utf-8').split('...')[1].replace('-','').replace(' ','')\n",
    "        #obtain_news_detail()\n",
    "        result_str = result_str + news_title + ',' + str(news_url) + ',' + news_date + '\\n'\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_search_result(result):\n",
    "    output = open('result_list.csv', 'w')\n",
    "    have_result = result.find('div', {'class':'nors'})\n",
    "    if have_result != None:\n",
    "        print \"No result found under current condition\"\n",
    "        return -1\n",
    "    else:\n",
    "        result_number = result.find('span', {'class':'support-text-top'}).getText().encode('utf-8')\n",
    "        result_number =  int(re.sub('[^0-9]','',result_number))\n",
    "        if result_number > 750:\n",
    "            max_page=74\n",
    "        else:\n",
    "            max_page = result_number / 10\n",
    "    result_object_list = result.findAll('div', {'class':'result f s0'})\n",
    "    result_str  =''\n",
    "    result_str = extract_search_information(result_object_list)\n",
    "    output.write(result_str)\n",
    "    i = 0\n",
    "    while i < max_page:\n",
    "        result_str = ''\n",
    "        page_id = i+1\n",
    "        next_query = construct_search_query(page_id, my_key_words, search_url)\n",
    "        try:\n",
    "            search_result = obtain_page_html(next_query)\n",
    "            original_search_html = open('original_html/search_' + str(i) + '.htm', 'w')\n",
    "            original_search_html.write(str(search_result))\n",
    "            original_search_html.close()\n",
    "            result_object_list = search_result.findAll('div', {'class':'result f s0'})\n",
    "            result_str = extract_search_information(result_object_list)\n",
    "            i = i + 1\n",
    "        except BadStatusLine:\n",
    "            print \"BadStatusLine; retrying\"\n",
    "        output.write(result_str)\n",
    "    output.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_news_detail(news_list):\n",
    "    detail_output = open('news_detail.csv', 'a')\n",
    "    scraped_list = file('scraped_list.csv', 'r').readlines()\n",
    "    scraped_output = open('scraped_list.csv', 'a')\n",
    "    news_id = len(scraped_list)\n",
    "    for news_info in news_list:\n",
    "        # catch httperror to handle 404\n",
    "        try:\n",
    "            news_detail = ''\n",
    "            scraped = ''\n",
    "            news = news_info.split('|')\n",
    "            if len(news) == 1:\n",
    "                print news\n",
    "            if (str(news[1]) + '\\n') not in scraped_list and 'v.gmw.cn' not in news[1]:\n",
    "                news_html = obtain_page_html(news[1])\n",
    "                if news_html.find('body', {'xmlns':'http://www.w3.org/1999/xhtml'}) != None:\n",
    "                    news_content = news_html.find('body', {'xmlns':'http://www.w3.org/1999/xhtml'}).getText().encode('utf-8').replace('\\n','').replace('\\r','')\n",
    "                elif news_html.find('div', {'id':'contentMain'}) != None:\n",
    "                    news_content = news_html.find('div', {'id':'contentMain'}).getText().encode('utf-8').replace('\\n','').replace('\\r','')\n",
    "                elif news_html.find('div', {'id':'ArticleContent'}) != None:\n",
    "                    news_content = news_html.find('div', {'id':'ArticleContent'}).getText().encode('utf-8').replace('\\n','').replace('\\r','')\n",
    "                elif news_html.find('td', {'id':'body'}) != None:\n",
    "                    news_content = news_html.find('td', {'id':'body'}).getText().encode('utf-8').replace('\\n','').replace('\\r','')\n",
    "                else:\n",
    "                    print 'new content format'\n",
    "                    detail_output.close()\n",
    "                    return 0\n",
    "                news_detail = news_detail + news[0] + '|' + news[1] + '|' + news[2].replace('\\n','') + '|' + news_content + '\\n'\n",
    "                detail_output.write(news_detail)\n",
    "                original_html = open('original_html/' + str(news_id) + '.htm', 'w')\n",
    "                original_html.write(str(news_html))\n",
    "                original_html.close()\n",
    "                scraped = news[1] + '\\n'\n",
    "                scraped_output.write(str(scraped))\n",
    "            else:\n",
    "                print \"scraped\"\n",
    "            news_id = news_id + 1\n",
    "        except urllib2.HTTPError, err:\n",
    "            print \"page not found\"\n",
    "            news = news_info.split('|')\n",
    "            scraped = news[1] + '\\n'\n",
    "            scraped_output.write(str(scraped))\n",
    "    detail_output.close()\n",
    "    scraped_output.close()\n",
    "    print \"news detail collected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_html_file(file_name, content):\n",
    "    return 0\n",
    "\n",
    "def construct_output_file_name(my_key_words, search_url, begin_time, end_time, search_mode, source):\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=0&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=1&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=2&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=3&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=4&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=5&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=6&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=7&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=8&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=9&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=10&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=11&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=12&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=13&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=14&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=15&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=16&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=17&s=16378496155419916178&entry=1&area=2\n",
      "BadStatusLine; retrying\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=17&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=18&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=19&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=20&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=21&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=22&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=23&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=24&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=25&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=26&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=27&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=28&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=29&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=30&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=31&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=32&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=33&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=34&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=35&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=36&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=37&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=38&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=39&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=40&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=41&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=42&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=43&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=44&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=45&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=46&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=47&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=48&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=49&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=50&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=51&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=52&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=53&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=54&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=55&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=56&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=57&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=58&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=59&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=60&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=61&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=62&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=63&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=64&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=65&s=16378496155419916178&entry=1&area=2\n",
      "BadStatusLine; retrying\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=65&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=66&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=67&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=68&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=69&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=70&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=71&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=72&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=73&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n",
      "start download from\n",
      "http://zhannei.baidu.com/cse/search?q=日本+地震&p=74&s=16378496155419916178&entry=1&area=2\n",
      "Page obtained\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "# Obtain current date\n",
    "    dt = str(datetime.date.today() - datetime.timedelta(days=1)).replace('-', '')\n",
    "    '''\n",
    "    my_query = construct_search_query(0, my_key_words, search_url)\n",
    "    search_result = obtain_page_html(my_query)\n",
    "    parse_search_result(search_result)\n",
    "    '''\n",
    "    news_list = file('result_list.csv', 'r').readlines()\n",
    "    extract_news_detail(news_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
